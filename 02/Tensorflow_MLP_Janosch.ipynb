{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation \n",
    "from math import e\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+e**x)\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set\n",
    "import numpy as np\n",
    "\n",
    "input_val = np.asarray([[0, 0],\n",
    "                        [0, 1],\n",
    "                        [1, 0],\n",
    "                        [1, 1]])\n",
    "\n",
    "target_or = np.asarray([[0],\n",
    "                        [1],\n",
    "                        [1],\n",
    "                        [0]])\n",
    "\n",
    "target_xor = np.asarray([[0],\n",
    "                         [1],\n",
    "                         [0],\n",
    "                         [1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron implementation\n",
    "class Perceptron():\n",
    "    def __init__(self, input_units:int, bias=True, act_func=sigmoid, alpha=0.01):\n",
    "        \n",
    "        # initialize weights\n",
    "        if bias:\n",
    "            self.weights = np.random.randn(input_units+1)\n",
    "        else:\n",
    "            self.weights = np.random.randn(input_units)\n",
    "        \n",
    "        # set learning rate\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # set activation function\n",
    "        self.act_func = act_func\n",
    "        \n",
    "        # allocating space for variables\n",
    "        self.drive = int()\n",
    "        self.activation = int()\n",
    "        \n",
    "    def fwd_step(self, inputs):\n",
    "        self.inputs = np.insert(inputs, 0, 1)\n",
    "        self.drive = self.weights @ self.inputs\n",
    "        self.activation = self.act_func(self.drive)\n",
    "        return self.activation\n",
    "    \n",
    "    def update(self, delta):\n",
    "        self.weights -= self.alpha * (self.inputs * delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP implementation\n",
    "class MLP():\n",
    "    def __init__(self, dim, act_func=sigmoid, act_func_prime=sigmoid_prime):\n",
    "        self._dim = dim\n",
    "        self.layers = [[Perceptron(self._dim[n], act_func=act_func) for _ in range(l)] for n, l in enumerate(self._dim[1:])]\n",
    "        self.output = [0 for _ in range(self._dim[-1])]\n",
    "        self.act_func_prime = sigmoid_prime\n",
    "        \n",
    "    def fwd_step(self, inputs):\n",
    "        assert len(inputs) == self._dim[0]\n",
    "        \n",
    "        self.activations = [inputs]\n",
    "        for layer in self.layers:\n",
    "            activation = []\n",
    "            for perceptron in layer:\n",
    "                activation.append(perceptron.fwd_step(self.activations[-1]))\n",
    "            self.activations.append(activation)\n",
    "    \n",
    "    def backprop(self, target):\n",
    "        assert len(target) == self._dim[-1]\n",
    "        \n",
    "        self.errors = []\n",
    "        # initial layer\n",
    "        error = []\n",
    "        for n, (target, output) in enumerate(zip(target, self.activations[-1])):\n",
    "            error.append(-(target-output)*self.act_func_prime(self.layers[-1][n].drive))\n",
    "        self.errors.append(error)\n",
    "                \n",
    "        for n, layer in enumerate(reversed(self.layers[1:])):\n",
    "            # other layers\n",
    "            layer_errors = np.zeros(len(layer[0].weights[1:]))\n",
    "            for i, (perceptron, error) in enumerate(zip(layer, self.errors[-1])):\n",
    "                layer_errors[i] = np.sum(error*np.asarray(perceptron.weights[1:]))*self.act_func_prime\n",
    "            self.errors.append(layer_errors)\n",
    "        \n",
    "        \n",
    "        for i, perceptron in enumerate(self.layers[-1]):\n",
    "            perceptron.update(self.errors[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP([2, 4, 2, 1])\n",
    "mlp.fwd_step([1, 1])\n",
    "mlp.backprop([1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
