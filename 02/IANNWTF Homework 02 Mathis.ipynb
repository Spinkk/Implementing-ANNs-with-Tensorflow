{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define the possible inputs for the logical operators in an array x and create arrays for 5 logical operators specifying which elements of x as inputs evaluate as True and which of them evaluate as False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "target_and = np.array([0,0,0,1])\n",
    "target_or = np.array([0,1,1,1])\n",
    "target_nand = np.array([1,1,1,0])\n",
    "target_xor = np.array([0,1,1,0])\n",
    "target_nor = np.array([1,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define some functions that we will use. We define the sigmoid and it's derivative where we define the derivative without referring to the sigmoid function to make use of previously computed activation values in the backpropagation scheme. \n",
    "\n",
    "We also define a function to evaluate the accuracy of our logical-gate model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-1*x))\n",
    "\n",
    "def sigmoid_prime(sigm):\n",
    "    \"\"\"\n",
    "    If sigm is the result of sigmoid(x), this computes the derivative of sigmoid(x)\n",
    "    \"\"\"\n",
    "    return sigm*(1-sigm)\n",
    "\n",
    "def accuracy_func(t, y_hat):\n",
    "    if ((t==1) and (y_hat>=0.5)) or ((t==0) and (y_hat<0.5)):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a class for individual Perceptrons. These will be the basis for our MLP. Each Perceptron can be thought of as a unit with inputs that are taken into a weighted sum by the weights that are are stored in a variable of the Perceptron. These weights are a 1D array (or a vector) and they contain at index 0 the Perceptron's bias. So we incorporated the bias into the weights, which means we also have to add an additional value of 1 at index 0 to the Perceptron's inputs.\n",
    "\n",
    "The result is called the Perceptron's drive on which an activation function (here by default set to be the sigmoid function) is applied, the result of which is called the Perceptron's activation.\n",
    "\n",
    "The idea of storing the activation and drive inside the neuron is so we can reuse these values, saving computational cost of computing them again. \n",
    "\n",
    "Finally we also define an update method for the Perceptron's weights (including the bias). This update method needs the error signal (delta) of the Perceptron. It can be understood as the contribution to the network error of this unit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, input_units, lr, act_func= sigmoid):\n",
    "        # set number of inputs\n",
    "        self.input_units = input_units\n",
    "        \n",
    "        # initialize weighted connections from inputs to the Perceptron\n",
    "        self.weights = np.random.randn(input_units +1) # +1 for bias weights\n",
    "        \n",
    "        # set learning rate\n",
    "        self.lr = lr\n",
    "        \n",
    "        # initialize activation function variable\n",
    "        self.act_func = act_func\n",
    "        \n",
    "        # to keep track of this Perceptron's drive and activation, initialize variables for drive\n",
    "        # and the inputs it receives.\n",
    "        self.drive = 0\n",
    "        self.inputs = 0\n",
    "        self.activation = 0\n",
    "        \n",
    "        # initialize the error signal for the perceptron\n",
    "        self.delta = None\n",
    "        \n",
    "    def forward_step(self, inputs):\n",
    "        \"\"\"\n",
    "        Performs a forward step for the perceptron.\n",
    "        \"\"\"\n",
    "        \n",
    "        # insert a value of 1 as the first entry in the perceptrons inputs \n",
    "        #(activations from previous layer or the MLPs input) for the bias \n",
    "        self.inputs = np.insert(inputs,0,1)\n",
    "        \n",
    "        # calculate the weighted sum of inputs weighted by their weights\n",
    "        self.drive =  self.weights @ self.inputs\n",
    "        \n",
    "        # return the activation for the Perceptron given the inputs and weights(including bias)\n",
    "        self.activation = self.act_func(self.drive)\n",
    "        return self.activation\n",
    "    \n",
    "    def update(self, delta):\n",
    "        \"\"\"\n",
    "        This will allow to update weights associated with this perceptron given that we have it's delta.\n",
    "        \"\"\"\n",
    "        \n",
    "        # compute gradients of the weights to this perceptron (including bias) by multiplying it's error signal with\n",
    "        # the it's unweighted inputs (including a 1 at index 0 for the bias weights)\n",
    "        gradient_weights = delta * self.inputs\n",
    "        \n",
    "        # update the weights (including bias) by subtracting learning rate * gradients \n",
    "        self.weights -= self.lr * gradient_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea now is to rely on this class of individual Perceptrons with their own weights (connections to the Perceptron's input) for building a neural network, a multi-layer-perceptron, MLP.\n",
    "\n",
    "We define this class such that it is possible to specify the input dimensions, the number of hidden layers and the output dimensions (though with the current activation functions applied to output units, it is intended to use only one output). \n",
    "\n",
    "An MLP consists of hidden layers, where the first layer is connected to the input, and the output units. For each hidden layer we instantiate the number of Perceptrons given by the argument total_dim. We make sure that the number of weights of these Perceptrons matches the number of Perceptrons or input units in the previous layer. \n",
    "\n",
    "Since each Perceptron can compute it's drive and activation given that we already know the previous activations/inputs, in the MLP-forward-step, we just go through the hidden units layer by layer and in each layer unit by unit and calculate their outputs (these are then stored in the Perceptron objects activation variable). Finally we obtain the outputs of the output neurons. \n",
    "\n",
    "The weights were initialized randomly in the Perceptron class, the outputs will probably not match the true target value (e.g.for the logical operator \"a and b\" a=1,b=1 should evaluate to True). This is why we use the backpropagation method to calculate the error signals for all hidden and output units. To propagate the error signal from the output units back to the  hidden units in the first hidden layer, we use these two formulas:\n",
    "\n",
    "For the output units, this is a rather simple.\n",
    "$\\delta_i^{(l)}$ = $-(t_i - y_i)$ $\\sigma^{'}(d_i^{(N)})$\n",
    "\n",
    "For the Perceptron units in the layers before the output all the way until the input layer we use this formula to compute the error signals:\n",
    "\n",
    "$\\delta_i^{(l)} = (\\sum_{k = 1}^{m} \\delta_k^{(l+1)} w_{ki}^{(l+1)}) \\sigma^{'}(d_i^{(l)})$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Having obtained the error signals, we can finally update the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    \"\"\"\n",
    "    input dimensions, hidden dimensions and output dimensions given as lists in distinct arguments\n",
    "    \"\"\"\n",
    "    def __init__(self, total_dim, alpha = 0.01):\n",
    "        \n",
    "        input_dim = total_dim[0]\n",
    "        hidden_dim = total_dim[1:-1]\n",
    "        output_dim = total_dim[-1]\n",
    "        \n",
    "        # create a nested list of Perceptrons where each perceptron has the input_units set to \n",
    "        # the previous layer's number of units (including input units at n=0)\n",
    "        self.hidden_layers = [\n",
    "                [Perceptron(input_units = total_dim[n],lr = alpha) for _ in range(layer_units)] \n",
    "                 for n, layer_units in enumerate(hidden_dim)\n",
    "        ]\n",
    "        \n",
    "        # initialize perceptrons for the output units (in case we have multiple outputs)\n",
    "        self.output_units = [Perceptron(input_units = hidden_dim[-1], lr = alpha) for _ in range(output_dim)]\n",
    "        \n",
    "        # initialize MLP output to 0 and initialize an empty list for individual layer's perceptron's activations\n",
    "        self.output = [0 for _ in range(output_dim)]\n",
    "        self.layer_activations = []\n",
    "        \n",
    "    \n",
    "    def forward_step(self, inputs):\n",
    "        \"\"\"\n",
    "        Perform a forward step given inputs\n",
    "        \"\"\"\n",
    "        # make sure inputs match the input_units for the first hidden layer perceptrons.\n",
    "        assert len(inputs) == len(self.hidden_layers[0][0].weights) - 1,'input dimension should match the initalisation'\n",
    "        \n",
    "        self.layer_activations = [inputs]\n",
    "        \n",
    "        # for each layer calculate the activation for all it's perceptrons. \n",
    "        # Then store these activations in a list and store this list in a list for all layer's activations.\n",
    "        for layer in self.hidden_layers:\n",
    "            activations = []\n",
    "            for unit in layer:\n",
    "                unit_activation = unit.forward_step(self.layer_activations[-1])\n",
    "                activations.append(unit_activation)\n",
    "            self.layer_activations.append(activations)\n",
    "        \n",
    "        # calculate output\n",
    "        self.output = [out_unit.forward_step(self.layer_activations[-1]) for out_unit in self.output_units]\n",
    "        \n",
    "    def backprop_step(self, targets):\n",
    "        \n",
    "        error_signals = []\n",
    "        # Start by calculating error signals for the output units.\n",
    "        \n",
    "        # For this we use the formula delta_i = -(target_i - output_i) * sigmoid_prime(drive of output unit_i)\n",
    "        # create a nested list for the deltas in each layer\n",
    "        error_signals = []\n",
    "        output_deltas = []\n",
    "        for i, (target, output) in enumerate(zip(targets,self.output)):\n",
    "            \n",
    "            # we want to reuse the activation values and not recompute the sigmoid\n",
    "            delta_i = -(target - output) * (sigmoid_prime(self.output_units[i].activation))\n",
    "            \n",
    "            #store delta in a variable of the perceptron unit\n",
    "            self.output_units[i].delta = delta_i\n",
    "            \n",
    "            # append error signal to output error signals list\n",
    "            output_deltas.append(delta_i)\n",
    "            \n",
    "            # perform weight update for output unit i using the error signal associated with this unit\n",
    "            self.output_units[i].update(delta_i)\n",
    "            \n",
    "        error_signals.append(output_deltas)\n",
    "        \n",
    "        # now compute the error signals for the hidden layers, \n",
    "        # to do this, we compute the sums for all units in a layer simultaneously and then multiply\n",
    "        # the corresponding sum_i for unit_i in layer l with the sigmoid derivative of unit_i's drive.\n",
    "        \n",
    "        for n, layer in enumerate(reversed(self.hidden_layers)):\n",
    "            # initialize a list of error signals for this layer\n",
    "            layer_deltas = []\n",
    "            sums_for_layer = np.zeros(len(layer))\n",
    "            \n",
    "            # since output units and hidden units are stored in independent variables, we have a\n",
    "            # slightly different procedure for n == 0.\n",
    "            \n",
    "            if n == 0:\n",
    "                for o_unit_k in self.output_units:\n",
    "                    sums_for_layer += o_unit_k.delta * np.array(o_unit_k.weights[1:])\n",
    "                \n",
    "                for i, sum_i in enumerate(sums_for_layer):\n",
    "                    # multiply the sum for unit i by the sigmoid derivative of it's drive to obtain it's delta\n",
    "                    delta = sum_i * sigmoid_prime(layer[i].activation)\n",
    "                    layer_deltas.append(delta)\n",
    "                    layer[i].delta = delta\n",
    "                error_signals.append(layer_deltas)\n",
    "                    \n",
    "            else:\n",
    "                # for hidden layer n that aren't connected to the output layer\n",
    "                for hidden_unit_k in self.hidden_layers[::-1][n-1]: # [::-1] for reversal of list, n-1 to \n",
    "                    sums_for_layer += hidden_unit_k.delta * np.array(hidden_unit_k.weights[1:])\n",
    "                    \n",
    "                for i, sum_i in enumerate(sums_for_layer):\n",
    "                    delta = sum_i * sigmoid_prime(layer[i].activation)\n",
    "                    layer_deltas.append(delta)\n",
    "                    layer[i].delta = delta\n",
    "                \n",
    "                error_signals.append(layer_deltas)\n",
    "        \n",
    "        # once we have all the deltas computed without having updated weights in between \n",
    "        #(this would distort the process), we update the weights.\n",
    "        \n",
    "        # update unit using the delta we assigned to it\n",
    "        for unit in self.output_units:\n",
    "            unit.update(unit.delta)\n",
    "            \n",
    "        for layer in self.hidden_layers:\n",
    "            for unit in layer:\n",
    "                unit.update(unit.delta) \n",
    "        \n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a test for accuracy of this architecture/implementation trained on the 5 different logical connectors. We show that the network is able to learn all of the logical operators with 100% (4/4 correct) accuracy.\n",
    "\n",
    "We train using stochastic gradient descent (batch size = 1) with 1000 epochs over 4 training examples for each operator.\n",
    "\n",
    "The MLP has 2 input units, 4 hidden units in one layer and 1 output unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy for and is: 1.0\n",
      "final accuracy for or is: 1.0\n",
      "final accuracy for nand is: 1.0\n",
      "final accuracy for xor is: 1.0\n",
      "final accuracy for nor is: 1.0\n"
     ]
    }
   ],
   "source": [
    "logs = {} # create dictionary to store results in\n",
    "\n",
    "# for each logical operator, compute for each epoch the avg losses and accuracies\n",
    "\n",
    "for name, logical_operator in [(\"and\", target_and), (\"or\", target_or), (\"nand\",target_nand), (\"xor\",target_xor), \n",
    "                               (\"nor\",target_nor)]:\n",
    "    \n",
    "    \n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    avg_loss = np.array([])\n",
    "    avg_accuracies= np.array([])\n",
    "    \n",
    "    # instantiate a MLP with 2 inputs, 1 hidden layer with 4 units and 1 output unit\n",
    "    \n",
    "    # set learning rate to 0.2 instead of 0.01 to achieve better results in 1000 epochs\n",
    "    learning_rate = 0.2\n",
    "    mlp = MLP([2,4,1], alpha= learning_rate)\n",
    "    \n",
    "    # train for 1000 epochs\n",
    "    epochs = 1000\n",
    "    \n",
    "    a = np.arange(len(x)) # define possible indices for shuffling\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # shuffling x and targets in each epoch\n",
    "        random.shuffle(a)\n",
    "        x_shuffled = x[a]\n",
    "        y_shuffled= logical_operator[a]\n",
    "\n",
    "        #training on each observation(x and y pair)\n",
    "        for x_i,t_i in zip(x_shuffled,y_shuffled):\n",
    "            mlp.forward_step(x_i)\n",
    "            mlp.backprop_step([t_i])\n",
    "\n",
    "        # compute accuracy for the current epoch and append to accuracies list.\n",
    "        # also compute the total squared error for an epoch\n",
    "        accuracy = 0\n",
    "        loss = 0\n",
    "        for x_i,y_i in zip(x,logical_operator):\n",
    "            mlp.forward_step(x_i)\n",
    "            accuracy += accuracy_func(y_i, mlp.output[0])\n",
    "            \n",
    "            loss += (y_i - mlp.output[0])**2\n",
    "            \n",
    "        accuracy= accuracy/len(x)\n",
    "        accuracies.append(accuracy)\n",
    "        losses.append(loss)\n",
    "        # compute the average accuracy and loss for current epoch.\n",
    "        avg_accuracies = np.append(avg_accuracies, np.mean(accuracies))\n",
    "        avg_loss = np.append(avg_loss, np.mean(losses))\n",
    "        \n",
    "    logs[name] = {\"losses\": losses, \"accuracies\": accuracies, \"avg_loss\":avg_loss,\n",
    "                  \"avg_accuracies\": avg_accuracies}\n",
    "    \n",
    "    print(\"final accuracy for\", name, \"is:\",accuracies[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a37e415548>"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "what_to_plot = \"xor\" # change this to view results for other logical operators\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(10,6))\n",
    "\n",
    "ax.plot(logs[what_to_plot][\"avg_accuracies\"])\n",
    "ax.set(title='Epoch average accuracy and loss ', xlabel = 'epoch')\n",
    "ax.plot(logs[what_to_plot][\"avg_loss\"])\n",
    "ax.legend([\"average accuracies\",\"average loss\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
