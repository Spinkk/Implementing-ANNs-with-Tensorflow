{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN w08.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPaLoV1SklM8FYih2CZwaDW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Spinkk/Implementing-ANNs-with-Tensorflow/blob/main/w08/ANN_w08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQMl9xwhunFx"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw7fGHNsuqrt"
      },
      "source": [
        "1. Data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il0wT7Kqusdf"
      },
      "source": [
        "def preprocess_tfds(dataset, batch_size=32, buffer_size=1024, prefetch_factor=tf.data.experimental.AUTOTUNE, shuffle=True):\n",
        "    '''\n",
        "    Create an input pipeline from tf.dataset. \n",
        "    Adjusted to only take input as there are no labels for autoencoders.\n",
        "    Does only do input pipeline optimization when desired (inputs are not None)\n",
        "\n",
        "    :param dataset: tf.dataset to preprocess\n",
        "    :param batch_size: int, default batch size is 32\n",
        "    :param buffer_size: int, default is 1024\n",
        "    :param prefetch_factor: int, default prefetch size is TF autotune\n",
        "    :returns: preprocessed tf.dataset\n",
        "    ''' \n",
        "    \n",
        "    # only use batching if shuffle is set to False\n",
        "    if not shuffle:\n",
        "        dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    else:\n",
        "        dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
        "    \n",
        "    # casting of the images to float32 and expanding dim since there is no channel dim\n",
        "    # dividing by 255 to min-max scale the input\n",
        "    # drop the label is it is not needed\n",
        "    dataset = dataset.map(lambda img, label: tf.cast(img, tf.float32)/255, \n",
        "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    # prefetch the dataset using AUTOTUNE to automatically find the optimal number of batches to prefetch\n",
        "    if not prefetch_factor is None:\n",
        "        dataset = dataset.prefetch(prefetch_factor)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "## label codes for later analysis/visualization of encoded dataset\n",
        "label_code = ['T-Shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']\n",
        "\n",
        "# load the entire dataset from tfds (you can also get fashion_mnist from keras)\n",
        "train_ds, test_ds = tfds.load('fashion_mnist', \n",
        "                              split=['train', 'test'], \n",
        "                              as_supervised=True, \n",
        "                              shuffle_files=False)\n",
        "\n",
        "\n",
        "train_ds = preprocess_tfds(train_ds)\n",
        "test_ds = preprocess_tfds(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k52Ayp3QvWpN"
      },
      "source": [
        "# 2. Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A3clCshvWEL"
      },
      "source": [
        "class Discriminator(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.slayers = [\n",
        "                                           tf.keras.layers.Conv2D(filters=32,\n",
        "                                                                  kernel_size=3,\n",
        "                                                                  strides=(2,2),\n",
        "                                                                  input_shape=(None,28,28,1)),\n",
        "                                           tf.keras.layers.BatchNormalization(),\n",
        "                                           tf.keras.layers.Activation('relu'),\n",
        "                                           tf.keras.layers.Conv2D(filters=64,\n",
        "                                                                  kernel_size=3,\n",
        "                                                                  strides=(2,2)),\n",
        "                                           tf.keras.layers.BatchNormalization(),\n",
        "                                           tf.keras.layers.Activation('relu'),\n",
        "                                           tf.keras.layers.Flatten(),\n",
        "                                           # binary decision of fake/real data\n",
        "                                           tf.keras.layers.Dense(1, activation='sigmoid')]\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        for layer in self.slayers:\n",
        "            try:  # training argument only for BN layer\n",
        "                x = layer(x, training) \n",
        "            except:\n",
        "                x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Generator(tf.keras.Model):\n",
        "    def __init__(self, latent_dim=100, restore_shape=(7,7,64)):\n",
        "        super(Generator, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.slayers = [tf.keras.layers.Dense(units=int(tf.math.reduce_prod(restore_shape)),\n",
        "                                             input_shape=(latent_dim,)),\n",
        "                       tf.keras.layers.BatchNormalization(),\n",
        "                       tf.keras.layers.Activation('relu'),\n",
        "                       # reshape to 3 dim with depth dim again\n",
        "                       tf.keras.layers.Reshape(target_shape=restore_shape),\n",
        "                       # (2,2) strided transposed conv to upsample        \n",
        "                       tf.keras.layers.Conv2DTranspose(filters=32,\n",
        "                                                       kernel_size=(3,3),\n",
        "                                                       strides=(2,2),\n",
        "                                                       padding='same'),\n",
        "                       tf.keras.layers.BatchNormalization(),\n",
        "                       tf.keras.layers.Activation('relu'),\n",
        "                       # restore image by convolution with image size\n",
        "                       tf.keras.layers.Conv2DTranspose(filters=1,\n",
        "                                                       kernel_size=(3,3),\n",
        "                                                       strides=(2,2),\n",
        "                                                       padding='same'),\n",
        "                       tf.keras.layers.BatchNormalization(),\n",
        "                       # use sigmoid to get values between 0 and 1\n",
        "                       tf.keras.layers.Activation('sigmoid')]\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        for layer in self.slayers:\n",
        "            try:  # training argument only for BN layer\n",
        "                x = layer(x, training) \n",
        "            except:\n",
        "                x = layer(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA23FsJryO5q",
        "outputId": "4e0bd888-4eb4-40c5-e4fe-a0a3abc45c77"
      },
      "source": [
        "exdis = Discriminator()\n",
        "for img in train_ds.take(1):\n",
        "    res = exdis(img)\n",
        "\n",
        "exgen = Generator()\n",
        "tf.shape(exgen(res))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([32, 28, 28,  1], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZADYX7iJhpEQ"
      },
      "source": [
        "# 3. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucURHyJI1vN2"
      },
      "source": [
        "class Timer():\n",
        "    \"\"\"\n",
        "    A small class to measure time during training.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self._start_time = None\n",
        "\n",
        "    def start(self):\n",
        "        \"\"\"\n",
        "        Start a new timer\n",
        "        \"\"\"\n",
        "        if self._start_time is not None:\n",
        "            print(f\"Timer is running. Use .stop() to stop it\")\n",
        "            return None\n",
        "\n",
        "        self._start_time = time.perf_counter()\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"\n",
        "        Stop the timer, and report the elapsed time\n",
        "        \"\"\"\n",
        "        if self._start_time is None:\n",
        "            print(f\"Timer is not running. Use .start() to start it\")\n",
        "            return 0\n",
        "    \n",
        "        elapsed_time = time.perf_counter() - self._start_time\n",
        "        self._start_time = None\n",
        "        return elapsed_time\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGXK-wkV1rXb",
        "outputId": "67157bc2-376e-4faf-cd24-a9a7777d1709"
      },
      "source": [
        "# Hyperparameters\n",
        "epochs = 10\n",
        "learning_rate = 0.0001\n",
        "latent_dim = 100\n",
        "\n",
        "tf.keras.backend.clear_session() #clear session from previous models\n",
        "timer = Timer() # Instantiate the timer\n",
        "\n",
        "# Instiante models\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "generator.build((None,latent_dim))\n",
        "discriminator.build((None,28,28,1))\n",
        "generator.summary()\n",
        "discriminator.summary()\n",
        "\n",
        "# Instantiate optimizer\n",
        "adam = tf.keras.optimizers.Adam(learning_rate) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                multiple                  316736    \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo multiple                  12544     \n",
            "_________________________________________________________________\n",
            "activation (Activation)      multiple                  0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran multiple                  18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch multiple                  128       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr multiple                  289       \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch multiple                  4         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    multiple                  0         \n",
            "=================================================================\n",
            "Total params: 348,165\n",
            "Trainable params: 341,827\n",
            "Non-trainable params: 6,338\n",
            "_________________________________________________________________\n",
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              multiple                  320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch multiple                  128       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    multiple                  0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            multiple                  18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch multiple                  256       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  2305      \n",
            "=================================================================\n",
            "Total params: 21,505\n",
            "Trainable params: 21,313\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS0LWQf1jRMc"
      },
      "source": [
        "def training_step_GAN(data, model_gen, model_disc, optimizer, metric_gen, metric_disc):\n",
        "    bce = tf.keras.losses.BinaryCrossentropy()\n",
        "    \n",
        "    for batch_true in data:\n",
        "        # Generate fake images\n",
        "        noise_in_z = tf.random.normal([tf.shape(batch_true)[0], model_gen.latent_dim])\n",
        "        batch_gen = model_gen(noise_in_z, training=True)\n",
        "\n",
        "        # Discriminator decides whether provided images are fake or not \n",
        "        fake_pred = model_disc(batch_gen, training=True)\n",
        "        true_pred = model_disc(batch_true, training=True)\n",
        "        \n",
        "        # Compute loss/gradient for discriminator\n",
        "        with tf.GradientTape() as tape:          \n",
        "            # discrminator should ideally assign 1 to true img and 0 to fake\n",
        "            loss_disc = bce(tf.zeros_like(fake_pred), fake_pred) + \\\n",
        "             bce(tf.ones_like(true_pred), true_pred) \n",
        "            # TODO: gradient isn't computed correctly although traininable variables are there\n",
        "            g_disc = tape.gradient(loss_disc, model_disc.trainable_variables)\n",
        "            print('g_disc', g_disc[0])\n",
        "        \n",
        "        # Compute loss/gradient for generator\n",
        "        with tf.GradientTape() as tape:\n",
        "            # generator should fool disc. that fake images are real (label 1)\n",
        "            loss_gen = bce(tf.ones_like(fake_pred), fake_pred)     \n",
        "            g_gen = tape.gradient(loss_gen, model_gen.trainable_variables)\n",
        "        \n",
        "        # Gradient descent\n",
        "        # TODO: \"No gradients provided for any variable:\"\n",
        "        optimizer.apply_gradients(zip(g_disc, model_disc.trainable_variables))\n",
        "        optimizer.apply_gradients(zip(g_gen, model_gen.trainable_variables))\n",
        "        \n",
        "        # Save mean loss values\n",
        "        metric_gen.update_state(loss_gen)\n",
        "        metric_disc.update_state(loss_disc)\n",
        "\n",
        "\n",
        "def evaluation_step_GAN(data, model_gen, model_disc, num_image=1):\n",
        "    '''\n",
        "    Plot generated image next to real image side by side\n",
        "    '''    \n",
        "\n",
        "    fig, ax = plt.subplots(nrows=num_image, ncols=2, figsize=(5*num_image, 10))\n",
        "     \n",
        "\n",
        "    for batch_img_true in data:\n",
        "        if tf.shape(batch_img_true)[0] < num_image:\n",
        "            print('NUM_IMAGE SHOULD BIG UNDER BATCH SIZE')\n",
        "            pass\n",
        "\n",
        "        # iterate over num_image img\n",
        "        for i,img_true in enumerate(batch_img_true[:num_image]): \n",
        "            noise_in_z = tf.random.normal([model_gen.latent_dim])\n",
        "            img_gen = model_gen(noise_in_z)\n",
        "            ax[i,0].imshow(img_true, cmap='gray')\n",
        "            ax[i,1].plot(img_gen, cmap='gray')\n",
        "        break  # just take the first batch \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANxUBhHV8UGn"
      },
      "source": [
        "# take mean over different data points in the training loop\n",
        "train_loss_gen = tf.keras.metrics.Mean('generator')\n",
        "train_loss_disc = tf.keras.metrics.Mean('discriminator')\n",
        "\n",
        "# initialize the logger for Tensorboard visualization\n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "train_log_dir = 'logs/gradient_tape/' + current_time + '/train_ResNet'      # defining the log dir\n",
        "test_log_dir = 'logs/gradient_tape/' + current_time + '/test_ResNet'        # defining the log dir\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)  # training logger\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)    # test logger\n",
        "\n",
        "# Initialize lists for later visualization.\n",
        "losses_disc = []\n",
        "losses_gen = []\n",
        "times = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "HcZeR2nm9f3T",
        "outputId": "5438b640-f206-4700-c809-09d34a779270"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    print(f'\\n[EPOCH] ____________________{epoch}____________________')\n",
        "    # Training\n",
        "    timer.start()\n",
        "    training_step_GAN(train_ds, generator, discriminator, adam, train_loss_disc, train_loss_gen)\n",
        "    # logging our metrics to a file which is used by tensorboard\n",
        "    with train_summary_writer.as_default():     \n",
        "        tf.summary.scalar('discriminator', train_loss_disc.result(), step=epoch)\n",
        "        tf.summary.scalar('generator', train_loss_gen.result(), step=epoch)\n",
        "    # append in epoch-wise history list\n",
        "    train_losses.append(train_loss_disc)\n",
        "    train_accuracies.append(train_loss_gen)\n",
        "    # reset metrics for next epoch use\n",
        "    train_loss_disc.reset_states()\n",
        "    train_loss_gen.reset_states()\n",
        "    # time and print progress\n",
        "    elapsed_time = timer.stop()\n",
        "    times.append(elapsed_time)\n",
        "    print(f'[{epoch}] - Finished Epoch in {elapsed_time:0.2f} seconds - train_loss: {train_loss:0.4f}, train_acc: {train_acc:0.4f}')\n",
        "    \n",
        "    # Test and visualize\n",
        "    timer.start()\n",
        "    evaluation_step_GAN(test_ds, generator, discriminator)\n",
        "    elapsed_time = timer.stop()\n",
        "    times.append(elapsed_time)\n",
        "    plt.show()\n",
        "    print(f'\\n[{epoch}] - Finished evaluation')\n",
        "  \n",
        "    # Print progress everywhile\n",
        "    if epoch%3 == 0:\n",
        "        print(f'\\n[INFO] - Total time elapsed: {np.sum(times)/60:0.4f} min. Total time remaining: {(np.sum(times)/(epoch+1))*(epochs-epoch-1)/60:0.4f} min.')\n",
        "print(f'[INFO] - Total run time: {np.sum(times)/60:0.4f} min.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[EPOCH] ____________________0____________________\n",
            "g_disc None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-f9995c50a739>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtraining_step_GAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_disc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# logging our metrics to a file which is used by tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrain_summary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-90c64cd092a7>\u001b[0m in \u001b[0;36mtraining_step_GAN\u001b[0;34m(data, model_gen, model_disc, optimizer, metric_gen, metric_disc)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Gradient descent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# TODO: \"No gradients provided for any variable:\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_disc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_disc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcross\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mreplica\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     \"\"\"\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_empty_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/utils.py\u001b[0m in \u001b[0;36mfilter_empty_gradients\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     raise ValueError(\"No gradients provided for any variable: %s.\" %\n\u001b[0;32m---> 79\u001b[0;31m                      ([v.name for _, v in grads_and_vars],))\n\u001b[0m\u001b[1;32m     80\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     logging.warning(\n",
            "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: ['conv2d/kernel:0', 'conv2d/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization_4/gamma:0', 'batch_normalization_4/beta:0', 'dense_1/kernel:0', 'dense_1/bias:0']."
          ]
        }
      ]
    }
  ]
}